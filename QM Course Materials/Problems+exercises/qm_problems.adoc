= Quantum Mechanics Problems and Exercises
:docinfo: shared
:toc: left
:nofooter:
:table-settings: pass:[cols="<1s,<4a,<4a",options="header",frame="all",stripes="even",grid="all"]
:imagesdir: images
:sectlinks:
:sectanchors:
:sch: Schrödinger
:toclevels: 3
:!webfonts:
:sublist-style: pass:[loweralpha]

https://dts333.github.io/WSF-Demos/QM%20Course%20Materials/Problems+exercises/qm_problems.html[This is a link to this very page.]


== Chapter 1

=== 1.1 The {sch} Equation
==== Questions
* *1.1.1* Question about demonstration (@Robert)

* *1.1.2* [Modified from Townsend] If \(\Psi_{n}\) is a solution to the {sch} equation, show that \(\Psi = \sum_{n}c_n \Psi_n\) is also a solution.
+
.Solution
[%collapsible]
====
Ultimately this is just due to the linearity of the differentiation operator and of ordinary multiplication.

If ++\(\Psi_n\)++ is a solution to the {sch} equation then ++\[-i\hbar \frac{\partial \Psi_{n}}{\partial t} - \frac{\hbar ^2}{2m}\frac{\partial ^2 \Psi_n}{\partial x^2}+ V(x)\Psi_n = 0\]++
Now for ++\(\Psi\)++,
++\[\begin{align*}
&\phantom{=}-i\hbar \frac{\partial \Psi}{\partial t} - \frac{\hbar ^2}{2m}\frac{\partial ^2 \Psi}{\partial x^2}+ V(x)\Psi\\
&= -i\hbar \frac{\partial }{\partial t}\sum_n c_n\Psi_n - \frac{\hbar ^2}{2m}\frac{\partial ^2 }{\partial x^2}\sum_n c_n\Psi_n + V(x)\sum_n c_n\Psi_n\\
& = \sum_n -i\hbar \frac{\partial }{\partial t}(c_n\Psi_n) - \sum_n \frac{\hbar ^2}{2m}\frac{\partial ^2 }{\partial x^2} (c_n\Psi_n) + \sum_n V(x) (c_n\Psi_n) \\
&= \sum_n c_n (-i\hbar \frac{\partial \Psi_n }{\partial t} -  \frac{\hbar ^2}{2m}\frac{\partial ^2 \Psi_n}{\partial x^2} +  V(x) \Psi_n )\\
&=\sum_n c_n \cdot 0= 0 \end{align*}\]++
We find that if ++\(\Psi_n\)++ is a solution to the {sch}, then ++\(\Psi = \sum_n c_n \Psi_n\)++ is also a solution to the {sch} equation.
====


* *1.1.3* [Modified from Townsend] Show that \(u(x,t) = A\cos(\omega t+ \phi) \sin(\frac{n\pi x}{l}) \) is a solution to the classical wave equation, \( \frac{1}{v^2}\frac{\partial ^2 u}{\partial t^2} = \frac{\partial ^2 u }{\partial x^2}\), but *not* the {sch} equation).
+
.Solution
[%collapsible]
====
For ++\(u(x,t)\)++ to be a solution to the classical wave equation, \( \frac{1}{v^2}\frac{\partial ^2 u}{\partial t^2} - \frac{\partial ^2 u }{\partial x^2} = 0\).
For ++\(u(x,t)\)++ to be a solution to the {sch} equation then \(-i\hbar \frac{\partial u}{\partial t} - \frac{\hbar ^2}{2m}\frac{\partial ^2 u}{\partial x^2}+ V(x)u = 0\).
Let's begin with the classical wave equation:
++\[\begin{align*}\frac{1}{v^2}\frac{\partial ^2 u}{\partial t^2} - \frac{\partial ^2 u }{\partial x^2} &= \frac{1}{v^2}\frac{\partial ^2}{\partial t^2}\left[A\cos(\omega t+ \phi) \sin\left(\frac{n\pi x}{l}\right)\right] - \frac{\partial ^2}{\partial x^2} \left[A\cos(\omega t+ \phi) \sin\left(\frac{n\pi x}{l}\right)\right] \\
&= -A\frac{\omega^2}{v^2}\cos(\omega t+ \phi) \sin\left(\frac{n\pi x}{l}\right) + A\left(\frac{n\pi}{l}\right)^2 \cos(\omega t+ \phi) \sin\left(\frac{n\pi x}{l}\right) \end{align*}\]++
We see that as long as \(v = \frac{\omega l}{n \pi}\) that \(u(x,t)\) is a solution to the classical wave equation. For the {sch} equation,
====

==== Demonstrations
* https://dts333.github.io/WSF-Demos/RB/src/dist/Quantum%20Mechanics/New%20demos/collapse_of_wavefunction_direction_and_momentum/collapse_of_wavefunction_direction_and_momentum_inlined.html[Collapse of Wavefunction Direction and Momentum]
** Notes: for this section, show just the position component; remove momentum.

==== Other Ideas, Notes, Materials

* Interactive timeline like the ones in some of our WSU courses (e.g., https://worldscienceu.com/lessons/1-4-from-einstein-to-ligo/[From Einstein to Ligo^]).


=== 1.2 The Statistical Interpretation

==== Questions

* *1.2.1* Let's derive some of the observed properties of the interference pattern in the double slit experiment. Suppose that the (monochromatic) light has a wavelength \(\lambda\), that the slits are a distance \(d\) apart, and that the detector screen is a distance \(D\gg d\) from the slits.
.. Show that at a point \(P\) an angle \(\theta\) from the center of the detector screen, the difference in path lengths between the slits' two respective waves is given by ++\(\Delta l=d\sin\theta\)++.
.. Show that the locations of maximum constructive interference (maximum intensity) are given by ++\(d\sin\theta=n\lambda\)++ for ++\(n\in\mathbb Z\)++.
.. Show that the locations of maximum destructive interference (minimum intensity) are given by ++\(d\sin\theta=\left(n+\frac{1}{2}\right)\lambda\)++ for ++\(n\in\mathbb Z\)++.
.. Using the assumption that \(D\gg d\) (and so the rays emanating from the two slits are approximately parallel), show that the distance from the center of the detector screen to the \(n\)^th^ crest is approximately \(\frac{n\lambda D}{d}\).

* *1.2.2* In which of the following variations of the double slit experiment will a wavelike interference pattern be observed?
** Using single photons
** Using single electrons
** Using a beam of electrons
** Measuring which slit the particle passes through
** Using helium atoms

+
.Solution
[%collapsible]
====
For the double slit experiment, all light and matter create a wavelike interference pattern, regardless of whether single particles are used or beams of particles are used. In quantum mechanics, wavelike interference is not an artifact of collective motion -- a single particle passes through both slits and interacts with _itself_! We see a wavelike interference pattern for a single photon, a single electron, a beam of electrons, or even helium atoms! However, if we set up an apparatus to measure which slit the particles travel through, we do _not_ observe an interference pattern because the wavefunctions collapse upon measurement.
====

==== Demonstrations
* Existing https://dts333.github.io/WSF-Demos/RB/src/dist/Quantum%20Mechanics/New%20demos/wavefunctions_and_probability_sampling_experiment/wavefunctions_and_probability_sampling_experiment_inlined.html?t=1653613543[Probability and Sampling Experiment^] and https://dts333.github.io/WSF-Demos/RB/src/dist/Quantum%20Mechanics/New%20demos/wavefunctions_and_probability_sampling_experiment_2D/wavefunctions_and_probability_sampling_experiment_2D_inlined.html?t=1653613543[Probability and Sampling Experiment (2D)^] demos
* https://dts333.github.io/WSF-Demos/RB/src/dist/Quantum%20Mechanics/New%20demos/wave_particle_duality_double_slit/wave_particle_duality_double_slit_inlined.html?t=1653613543[Double slit experiment — detector simulation^]

=== 1.3 Probability

* *1.3.1* An integer is chosen uniformly at random from the set ++\(\{0,1, 2,\ldots, 199\}\)++.
+
[{sublist-style}]
. What are the probabilities of selecting a number with 1, 2, or 3 digits?
. Calculate the expected number of digits.
. Find the standard deviation of the number of digits.

.Solution
[%collapsible]
====
[{sublist-style}]
. There are 10 possible 1-digit numbers, 90 possible 2-digit numbers, and 100 3-digit numbers. The probability of selecting a 1, 2, or 3 digit number are: ++\[P(\textrm{1}) = \frac{10}{200} = \frac{1}{20}\]++  ++\[P(\textrm{2}) = \frac{90}{200} = \frac{9}{20}\]++ ++\[P(\textrm{3}) = \frac{100}{200} = \frac{1}{2}\]++
. The expected number of digits is ++\[\begin{align*}\langle d \rangle &= (1)P(1)+(2)P(2) + (3)P(3) \\ &=  (1)\frac{1}{20}+ (2)\frac{9}{20}+(3)\frac{1}{2} \\ &=  2.45  \end{align*}\]++ If you choose a number at random, the expected value for the number of digits is 2.45.
. Standard deviation is given by \(\sqrt{\langle d^2\rangle - \langle d \rangle^2}\), where \(d\) is the number of digits that a selected number has. ++\[\begin{align*} \langle d^2 \rangle  =&  (1^2)P(1)+(2^2)P(2) + (3^2)P(3) \\ =&  (1)\frac{1}{20}+ (4)\frac{9}{20}+(9)\frac{1}{2} \\ =&  6.35 \end{align*}\]++ The standard devation is: ++\[\sigma = \sqrt{6.35-(2.45)^2} = 0.59\]++
====

* *1.3.2* You survey your neighbors to determine the number of pets they have in their households and collect the following data:
+
--
[#pets-table,cols=">1h,<1",stripes=none,frame=all,grid=rows,width=40em]
|===
|Number of pets in household
s|Number of households with that number of pets
|0|3
|1|6
|2|5
|3|2
|4|2
|5|0
|6|0
|7|1
|8|0
|9|0
|10|1
|===


Verify that both ways of computing standard deviation give the same answer (i.e. show that \(\sqrt{\langle (\Delta n)^2 \rangle} = \sqrt{\langle n^2 \rangle - \langle n \rangle ^2}\) where n is the number of pets in the household).

.Solution
[%collapsible]
====
Calculate \(\langle n \rangle\), \(\langle n^2 \rangle\), and \(\langle (\Delta n)^2 \rangle\)
++\[\begin{align*} \langle n \rangle =& 0(.15) + 1(.3) + 2 (.25)+ 3(.1)+ 4(.1) + \\ &5(0) + 6(0) + 7(.05) + 8(0) + 9(0) + 10(.05) \\=& 0+ .3 + .5 + .3 + . 4 + 0 + 0+ .35+ 0 + 0 +.5 \\=& 2.35 \end{align*}\]++ ++\[\begin{align*} \langle n^2 \rangle =& 0(.15) + 1(.3) + 4(.25)+ 9(.1)+ 16(.1) + \\ &25(0) + 36(0) + 49(.05) + 64(0) + 81(0) + 100(.05) \\=& 0+ .3 + 1 + .9 + 1.6  + 0 + 0+ 2.45 + 0 + 0 + 5 \\=&  11.25 \end{align*}\]++
++\[\begin{align*} \langle (\Delta n)^2) \rangle =& (0-2.35)^2(.15) + (1-2.35)^2(.3) +(2-2.35)^2(.25) +\\ &(3-2.35)^2(.1)+ (4-2.35)^2(.1) + (5-2.35)^2(0) +\\ &(6-2.35)^2(0) + (7-2.35)^2(.05) + (8-2.35)^2(0) +\\ &(9-2.35)^2(0) + (10-2.35)^2(.05) \\=& 0.828375 + 0.54675 + 0.030625 + 0.04225 + \\ & 0.27225 + 0 + 0 + 1.081125 + 0 + 0 + 2.926125\\ =& 5.7275 \end{align*}\]++
We find that \(\sqrt{\langle (\Delta n)^2 \rangle} = \sqrt{\langle n^2 \rangle - \langle n \rangle ^2} = 2.39\)
====
--

* *1.3.3* Plot the following two probability density distributions over the interval 0 to 1:
+
--
++\[\begin{align*}
\rho_1(x)&=
    \begin{cases}
        4x & 0\le x \le \frac{1}{2}\\
        -4x+4 & \frac{1}{2}\le x\le 1
    \end{cases}\\
    \rho_2(x) &= 2\sin^2(2\pi x)\end{align*}\]++

[{sublist-style}]
. Make a prediction: on your graphs, sketch a solid line where you think the expectation value of x will be and sketch dotted lines where you think the standard deviation will fall.
. Calculate ++\(\langle x \rangle\)++ and ++\(\sigma\)++ for both distributions.
. For both distributions, calculate the probability of finding the particle within 1 standard deviation.
--

* *1.3.4*

- Wording #1:
You are standing at the center of a number line (++\(x=0\)++). You flip a coin, and every time you flip heads, you take a unit step in the positive direction.
Every time you flip tails, you take a unit step in the negative direction.
[{sublist-style}]
. You flip the coin one time (++\(n=1\)++).
Where on the number line could you end up?
How many total paths are there?
. For ++\(n=0\)++ to ++\(n=3\)++, how many times could you end up at each integer?
How many total paths are there?
Do you notice a pattern?
. Use Pascal's triangle to determine the probability of landing at each integer after 7 steps.
Where are you most likely to land?
Calculate the expected value and standard deviation.

- Wording #2:
Beginning with ++\(x_0=0\)++, you repeatedly flip a fair coin ++\(n\)++ times.
For ++\(k=1,\ldots,n\)++, if the ++\(k\)++^th^ flip is heads, set ++\(x_k=x_{k-1}+1\)++.
If the ++\(k\)++^th^ flip is tails, set ++\(x_k=x_{k-1}-1\)++.
We will investigate the possible values of ++\(x_n\)++ and the number of sequences of coin flips resulting in ++\(x_n=N\)++, i.e., the number of sequences containing ++\(N\)++ more heads than tails (with more tails than heads if ++\(N<0\)++).
[{sublist-style}]
. What are the possible values of ++\(x_1\)++? How many total sequences of coin flips are there?
. For ++\(n=0\)++ to ++\(n=3\)++, how many sequences of coin flips lead to each possible value of ++\(N\)++?
How many sequences of coin flips are there in total?
Do you notice a pattern?
. Use https://en.wikipedia.org/wiki/Pascal's_triangle[Pascal's triangle^] to determine the probability of landing at each integer after 7 coin flips.
Where are you most likely to land?
Calculate the expected value and standard deviation.

+
.Solution (placeholder)
[%collapsible]
====
This is the solution
====

==== Demonstrations

* A discrete version of the above probability sampling demos, replacing the continuous functions with (say) balls in a bag, or dice, or whatever, and showing the same kind of histogram grow over time.
* A demonstration of example 1.2 (the falling object, sampling how far it has fallen).
* Show how the moments of various distributions depend on their parameters (e.g., show one standard deviation of a gaussian and how it changes with the parameter ++\(\sigma\)++).

==== Other Ideas, Notes, Materials

* Discuss basic properties of probability distributions:
** Linearity of expectation
** How scaling ++\(x\)++ affects ++\(\sigma\)++


=== 1.4 Normalization

==== Questions
* *1.4.1* Normalize the following wavefunctions (i.e. find A):
+
[{sublist-style}]
. ++\(\Psi(x,t)= Ae^{-(\frac{ax^2}{2}+i\omega t)}\)++
. ++\(\Psi(x,0)= Ae^{-\kappa|x|}\)++
. ++\(\Psi(x,0)= A\frac{\sin(x)}{x}\)++
. ++\(\Psi(x,t)= A\frac{e^{-i\omega t}}{x+e^{i \pi/2}}\)++

+
.Solution (placeholder)
[%collapsible]
====
This is the solution
====

* *1.4.2* Write a normalized wavefunction, ++\(\Psi(x,t)\)++,  with the following values at time ++\(t=0\)++ :
+
++\[\begin{align*}\langle x \rangle &= 3 \\\sigma &= 2\end{align*}\]++
+
.Solution (placeholder)
[%collapsible]
====
This is the solution
====

* *1.4.3* The probability current describes the rate at which probability flows past point ++\(x\)++. It is given by ++\[J(x,t) = \frac{i
    \hbar}{2m}\left(\Psi\frac{\partial\Psi^{*}}{\partial x}-\Psi^{*}\frac{\partial\Psi}{\partial x}\right)\]++

[{sublist-style}]
. Show that ++\[\ \frac{d}{dt} \int_a^b |\Psi(x,t)|^2 = J(a,t) - J(b,t) \]++ What happens to the probability current in the region from ++\(-\infty\)++ to ++\(\infty\)++? What does this mean?
. Use https://en.wikipedia.org/wiki/Divergence_theorem[Gauss's Theorem] to extend this result to an arbitrary region ++\(S\)++ in ++\(\mathbb R^n\)++.
. [From the Bernd Thaller book] Write ++\(\Psi(x,t)=|\Psi(x,t)|e^{i\varphi(x,t)}\)++.
Show that ++\(J\)++ as defined above points in the direction of ++\(\nabla \varphi\)++, i.e., in the direction of increasing phase.

=== 1.5 Momentum

==== Questions
* *1.5.1* For the following wavefunction ++\[\Psi(x,t) = e^{-i \lambda_1 t}\sin(\pi x) + e^{-i \lambda_2 t}\sin(2 \pi x) \]++
[{sublist-style}]
. Show that ++\(\Psi(x,t)\)++ is normalized.
. Calculate ++\(\langle x \rangle\)++ and ++\(\langle p \rangle \)++
. Calculate ++\(\frac{d \langle x \rangle}{dt}\)++. Does Ehrenfest's theorem hold?
. Find ++\(\langle - \frac{\partial V}{\partial x}\rangle \)++.

* *1.5.2* Show that in a quadratic potential ++\(V(x)=ax^2+bx+c\)++, the following holds:
++\[\frac{d\langle p \rangle}{dt}=-\left.\frac{\partial V}{\partial x}\right|_{x=\langle x\rangle}\]++
In other words, if the potential is quadratic then we can say "`the expectation of the force at ++\(x\)++ is the force evaluated at ++\(\langle x\rangle\)++`".
+

.Solution
[%collapsible]
====
Starting with Ehrenfest's theorem, all we need to do is compute ++\(-\frac{\partial V}{\partial x}\)++ and use the linearity of expectation:

++\[
\begin{align*}
\frac{d\langle p\rangle}{dt}&=\left\langle-\frac{\partial V}{\partial x}\right\rangle\\
&=\left\langle-(2ax+b)\right\rangle\\
&=-(2a\langle x\rangle + b)\\
&=-\left.\frac{\partial V}{\partial x}\right|_{x=\langle x\rangle}
\end{align*}
\]++

If \(V\) had any higher order \(x\) terms, then its derivative would have a term of order ++\(x^2\)++ or higher, and the above procedue wouldn't work because in general ++\(\langle x^n\rangle\ne\langle x\rangle^n\)++.
====

* *1.5.3* Any dynamical variable can be expressed in terms of position and momentum. Angular momentum is given by ++\[\textbf{L} = \textbf{r} \times \textbf{p}\]++ In this problem you will get a small preview of orbital angular momentum, which you will learn much more about in Module 4. We will be working in three dimensions, where ++\(\textbf{r} = r\hat{r}\)++ and ++\(\textbf{p} = -i \hbar \nabla \)++.
[{sublist-style}]
. Find the expression for ++\(\textbf{L}\)++ in spherical coordinates.
. Find ++\(L^2\)++.
. Calculate ++\(\langle L^2 \rangle\)++ for the spatial component of the wavefunction ++\( \sqrt{\frac{15}{8\pi}}\sin{\theta}\cos{\theta}e^{-i\phi} \)++


==== Demonstrations
* Demonstrate Ehrenfest's Theorem on various wavefunctions evolving over time by showing ++\(\langle x\rangle_\psi\)++ and ++\(\langle p\rangle_\psi\)++.
** [x] Harmonic oscillator: https://dts333.github.io/WSF-Demos/RB/src/dist/Quantum%20Mechanics/New%20demos/harmonic_oscillator/harmonic_oscillator_evolution_inlined.html?t=1653613543[the quantum harmonic oscillator^]
** [ ] Particle in a box
** [ ] others?
* Sample from these wavefunctions, e.g., let the harmonic oscillator evolve a bunch, then sample its position at a given point in time (pretending that we have an ensemble of identically prepared harmonic oscillators).
Let the resulting ++\(\delta\)++ function evolve (spread out, oscillate), then sample again. Etc.

=== 1.6 The Uncertainty Principle

==== Questions
placeholder

==== Demonstrations
* https://dts333.github.io/WSF-Demos/RB/src/dist/Quantum%20Mechanics/New%20demos/fourier_transform_gaussian/fourier_transform_gaussian_inlined.html?t=1653613543[Fourier Transformed Gaussian^]


=== Griffiths: Chapter 1 Questions

1.1:: For the distribution of ages in the example in Section 1.3.1:
+
[{sublist-style}]
. Compute ++\(\langle j^2 \rangle_\psi\)++ and ++\(\langle j \rangle ^2\)++
. Determine ++\(\Delta j\)++ for each ++\(j\)++, and use Equation 1.11 to compute the standard deviation.
. Use your results in (a) and (b) to check Equation 1.12.

1.2::
+
[{sublist-style}]
. Find the standard deviation of the distribution in Example 1.2.
. What is the probability that a photograph, selected at random, would
show a distance ++\(x\)++ more than one standard deviation away
from the average?

1.3:: Consider the *gaussian* distribution
++\[\rho(x)= Ae^{-\lambda(x-a)^2}\]++
where ++\(A\)++, ++\(a\)++, and ++\(\lambda\)++ are positive real constants. (The necessary integrals are inside the back cover.)
+
[{sublist-style}]
. Use Equation 1.16 to determine ++\(A\)++.
. Find ++\(\langle x \rangle\)++, ++\(\langle x^2 \rangle\)++, and ++\(\sigma\)++.
. Sketch the graph of ++\(\rho(x)\)++.

1.4:: At time ++\(t=0\)++ a particle is represented by the wave
function
+
\[\Psi(x,0)=
    \begin{cases}
        A(x/a), & 0\le x \le a,\\
        A(b-x)/A(b-a), & a \le x \le b,\\
        0, & \textrm{otherwise},
    \end{cases}\]
where ++\(A\)++, ++\(a\)++, and ++\(b\)++ are
(positive) constants.
+
[{sublist-style}]
. Normalize ++\(\Psi\)++ (that is, find ++\(A\)++ in terms
of ++\(a\)++ and ++\(b\)++).
. Sketch ++\(\Psi(x,0)\)++ as a function of ++\(x\)++.
. Where is the particle most likely to be found at ++\(t=0\)++?
. What is the probability of finding the particle to the left of
++\(a\)++? Check your result in the limiting cases
++\(b=a\)++ and ++\(b=2a\)++.
. What is the expectation value of ++\(x\)++?


1.5:: Consider the wave function
++\[\Psi(x,t)=Ae^{-\lambda|x|}e^{-i \omega t}\]++
where ++\(A\)++, ++\(\lambda\)++, and ++\(\omega\)++ are positive real constants.
(We'll see in Chapter 2 for what potential (++\(V\)++) this wave function satisfies the {sch} equation.)
+
[{sublist-style}]
. Normalize ++\(\Psi\)++.
. Determine the expectation values of ++\(x\)++ and ++\(x^2\)++.
. Find the standard deviation of ++\(x\)++.
+
Sketch the graph of ++\(|\Psi|^2\)++, as a function of ++\(x\)++, and mark the points ++\((\langle x \rangle + \sigma)\)++ and ++\((\langle x \rangle - \sigma)\)++, to illustrate the sense in which ++\(\sigma\)++ represents the "`spread`" in ++\(x\)++. What is the probability that the particle would be found outside this range?

1.6::
Why can't you do integration-by-parts directly on th emiddle expression in Equation 1.29 -- pull the time derivative over onto \(x\), note that ++\(\partial x / \partial t = 0\)++, and conclude that ++\(d\langle x \rangle / dt = 0\)++?

1.7:: Calculate ++\(\frac{d\langle p \rangle}{dt}\)++. Answer:
+
++\[\frac{d\langle p \rangle}{dt} = \left\langle- \frac{\partial V}{\partial x} \right\rangle.\]++
This is an instance of *Ehrenfest’s theorem*, which asserts that
_expectation values obey the classical laws_.


1.8:: Suppose you add a constant ++\(V_0\)++ to the
potential energy (by "`constant`" I mean independent of ++\(x\)++
as well as ++\(t\)++). In _classical_ mechanics this doesn't
change anything, but what about _quantum_ mechanics? Show that the wave
function picks up a time-dependent phase factor:
++\(\exp(-iV_0t/\hbar)\)++. What effect does this have on the
expectation value of a dynamical variable?

1.9:: A particle of mass ++\(m\)++ has the wave function
++\[\Psi(x,t) = Ae^{-a[(mx^2/\hbar)+it]},\]++
where ++\(A\)++ and ++\(a\)++ are positive real constants.
+
[{sublist-style}]
. Find ++\(A\)++.
. For what potential energy function, ++\(V(x)\)++, is this a
solution to the {sch} equation?
. Calculate the expectation values of ++\(x\)++,
++\(x^2\)++, ++\(p\)++, and ++\(p^2\)++.
. Find ++\(\sigma_{x}\)++ and ++\(\sigma_{p}\)++. Is their
product consistent with the uncertainty principle?

1.10::
+
Consider the first 25 digits in the decimal expansion of ++\(\pi\)++: ++\(3, 1, 4, 1, 5, 9, \ldots\)++.
+
[{sublist-style}]
. If you selected one number at random, from this set, what are the
probabilities of getting each of the 10 digits?
. What is the most probable digit? What is the median digit? What is the
average value?
. Find the standard deviation for this distribution.

1.11::
Griffiths:::
+
--
image::ch1_p1.11.jpg[width=225,role="related thumb right"]

[This problem generalizes Example 1.2.] Imagine a particle of mass ++\(m\)++ and energy ++\(E\)++ in a potential well ++\(V(x)\)++, sliding frictionlessly back and forth between the classical turning points (++\(a\)++ and ++\(b\)++ in Figure 1.10).

Classically, the probability of finding the particle in the range ++\(dx\)++ (if, for example, you took a snapshot at a random time ++\(t\)++) is equal to the fraction of the time ++\(T\)++ it takes to get from ++\(a\)++ to ++\(b\)++ that it spends in the interval ++\(dx\)++:

\[\rho(x)\,dx=\frac{dt}{T}=\frac{(dt/dx)\,dx}{T}=\frac{1}{v(x)T}\,dx,\]

where ++\(v(x)\)++ is the speed, and

\[T=\int_0^T dt = \int_a^b \frac{1}{v(x)}\,dx.\]

Thus
\[\rho(x)=\frac{1}{v(x)T}\]

This is perhaps the closest classical analog to ++\(|\Psi|^2\)++.
[{sublist-style}]
. Use conservation of energy to express ++\(v(x)\)++ in terms of ++\(E\)++ and ++\(V(x)\)++.
. As an example, find ++\(\rho(x)\)++ for the simple harmonic oscillator, ++\(V(x)=k x^2/2\)++. Plot ++\(\rho(x)\)++, and check that it is correctly normalized.
. For the classical harmonic oscillator in part (b), find ++\(\langle x\rangle\)++, ++\(\langle x^2\rangle\)++, and ++\(\sigma_x\)++.
--

1.11::
Griffiths:::
+
**{blank}*{blank}* 1.12** What if we were interested in the distribution of _momenta_
(++\(p=mv\)++) for the classical harmonic oscillator (Problem
1.11(b)).
+
[{sublist-style}]
. Find the classical probability distribution ++\(\rho(p)\)++
(note that ++\(p\)++ ranges from ++\(-\sqrt{2mE}\)++ to
++\(+\sqrt{2mE}\)++).
. Calculate ++\(\langle p \rangle\)++,
++\(\langle p^2 \rangle\)++, and ++\(\sigma_{p}\)++.
. What’s the _classical_ uncertainty product,
++\(\sigma_{x}\sigma_{p}\)++, for this system? Notice that this
product can be as small as you like, classically, simply by sending
++\(E \rightarrow 0\)++. But in quantum mechanics, as we shall see
in Chapter 2, the energy of a simple harmonic oscillator cannot be less
than ++\(\hbar \omega /2\)++, where
++\(\omega = \sqrt{k/m}\)++ is the classical frequency. In that
case what can you say abut the product
++\(\sigma_{x}\sigma_{p}\)++?

1.13::
Griffiths:::
+
--
Check your results in Problem 1.11(b) with the following “numerical experiment.” The position of the oscillator at time ++\(t\)++ is

\[x(t) = A\cos(\omega t)\]


You might as well take ++\(\omega=1\)++ (that sets the scale for time) and ++\(A=1\)++ (that sets the scale for length). Make a plot of ++\(x\)++ at 10,000 random times, and compare it with ++\(\rho[x\)++].
_Hint_: In Mathematica, first define

[source,mathematica]
----
x[t_] := Cos[t]
----

then construct a table of positions:

[source,mathematica]
----
snapshots = Table[x[𝜋 RandomReal[j]], {j, 10000}]
----

and finally, make a histogram of the data:

[source,mathematica]
----
Histogram[snapshots, 100, "PDF", PlotRange -> {0,2}]
----

Meanwhile, make a plot of the density function, ++\(\rho(x)\)++, and, using `Show`, superimpose the two.
--

1.14::
Griffiths:::
+
--
Let ++\(P_{ab}(t)\)++ be the probability of finding the
particle in the range ++\((a<x<b)\)++, at time ++\(t\)++.

[{sublist-style}]
. Show that \[\frac{dP_{ab}}{dt} = J(a,t) - J(b,t)\] where
++\[J(x,t) \equiv \frac{i
    \hbar}{2m}\left(\Psi\frac{\partial\Psi^{*}}{\partial x}-\Psi^{*}\frac{\partial\Psi}{\partial x}\right)\]++
What are the units of ++\(J(x,t)\)++? _Comment:_ ++\(J\)++
is called the *probability current* because it tells you the rate at
which probability is "`flowing`" past the point ++\(x\)++. If
++\(P_{ab}(t)\)++ is increasing, then more probability is flowing
into the region at one end than flows out the other.
. Find the probability current for the wave function in Problem 1.9.

(This is not a very pithy example, I’m afraid; we’ll encounter more
substantial ones in due course.)
--

1.15::
+
--
Show that

++\[\frac{d}{dt}\int_{-\infty}^{\infty}\Psi_{1}^{*}\Psi_{2}\,dx = 0\]++

for any two (normalizable) solutions to the same {sch} equation (i.e., with
the same ++\(V(x)\)++), ++\(\Psi_{1}\)++ and
++\(\Psi_{2}\)++.
--

1.16::
+
--
A particle is represented (at time ++\(t=0\)++) by the wave function

++\[
\Psi(x,0)=\begin{cases}
A(a^2-x^2)&-a\le x\le +a\\
0 &\textrm{otherwise}
\end{cases}
\]++
[{sublist-style}]
. Determine the normalization constant ++\(A\)++.
. What is the expectation value of ++\(x\)++?
. What is the expectation value of ++\(p\)++? (Note that you
_cannot_ get it from
++\(\langle p \rangle = m\frac{d\langle x \rangle}{dt}\)++. Why not?)
. Find the expectation value of ++\(x^2\)++.
. Find the expectation value of ++\(p^2\)++.
. Find the uncertainty in ++\(x\)++ (++\(\sigma_{x}\)++).
. Find the uncertainty in ++\(p\)++ (++\(\sigma_{p}\)++).
. Check that your results are consistent with the uncertainty principle.
--

1.17::
+
--
Suppose you wanted to describe an *unstable particle* that spontaneously
disintegrates with a "`lifetime`" ++\(\tau\)++. In that case the
total probability of finding the particle somewhere should _not_ be
constant, but should decrease at (say) an exponential rate:
++\[P(t) \equiv \int_{-\infty}^{\infty}|\Psi(x,t)|^2dx=e^{-t/\tau}\]++

A crude way of achieving this result is as follows. In Equation 1.24 we
tacitly assumed that V (the potential energy) is _real_. That is
certainly reasonable, but it leads to the "`conservation of
probability`" enshrined in Equation 1.27. What if we assign to
++\(V\)++ an imaginary part:
++\[V=V_{0}-i\Gamma\]++
where ++\(V_{0}\)++ is the true potential energy and
++\(\Gamma\)++ is a positive real constant?
[{sublist-style}]
. Show that (in place of Equation 1.27) we now get
++\[\frac{dP}{dt} = -\frac{2\Gamma}{\hbar}P.\]++

. Solve for ++\(P(t)\)++, and find the lifetime of the particle in
terms of ++\(\Gamma\)++.
--

1.18::
+
--
Very roughly speaking, quantum mechanics is relevant when the de Broglie
wavelength of the particle in question (++\(h/p\)++) is greater
than the characteristic size of the system (++\(d\)++). In thermal
equilibrium at (Kelvin) temperature ++\(T\)++, the average kinetic
energy of a particle is

++\[\frac{p^2}{2m} = \frac{3}{2}k_BT\]++

(where ++\(k_B\)++ is Boltzmann’s constant), so the typical de
Broglie wavelength is

++\[\lambda = \frac{h}{\sqrt{3mk_BT}}\]++

The purpose of this problem is to determine which systems will have to
be treated quantum mechanically and which can safely be described
classically.
[{sublist-style}]
. *Solids.* The lattice spacing in a typical solid is around
++\(d=0.3\,\textrm{mm}\)++. Find the temperature below which the unbound _electrons_ in a solid are quantum mechanical. Below what temperature are the _nuclei_ in a solid quantum mechanical? (Use silicon as an example.)
+
_Moral_: The free electrons in a solid are _always_ quantum mechanical; the nuclei are generally _not_ quantum mechanical. The same goes for liquids (in which the interatomic spacing is roughly the same), with the exception of helium below ++\(4\,\textrm{K}\)++.

. *Gases.* For what temperatures are the atoms in an ideal gas at pressure ++\(P\)++ quantum mechanical? Hint: Use the ideal gas law (++\(PV=Nk_BT\)++) to deduce the interatomic spacing.
_Answer_: ++\(T<(1/k_B)(h^2/3m)^{3/5}P^{2/5}\)++.
Obviously (for the gas to show quantum behavior) we want ++\(m\)++ to be as small as possible, and ++\(P\)++ as large as possible.
Put in the numbers for helium at atmospheric pressure.
Is hydrogen in outer space (where the interatomic spacing is about ++\(1\,\textrm{cm}\)++ and the temperature is ++\(3\,\textrm{K}\)++) quantum mechanical?
(Assume it's monatomic hydrogen, not ++\(\ce{H2}\)++.)
--

// Verify Ehrenfest's theorem for the following wavefunction:

//[stem]
//++++
//\Psi(x,t) = \left(\frac{a}{\pi}\right)^{\frac{1}{4}}e^{-(\frac{a x^2}{2}+i\omega t) }
//++++

//where

//[stem]
//++++
//a=\frac{m\omega}{\hbar}
//++++

// . Calculate ++\(\frac{d\langle p \rangle}{dt}\)++
// . Use Schrodinger's equation to find ++\(V(x)\)++.
// . Calculate ++\(\left\langle -\frac{\partial V}{\partial x} \right\rangle\)++. Does Ehrenfest's theorem hold?
// . This wavefunction is the ground state of the quantum harmonic oscillator, the quantum analog of a https://en.wikipedia.org/wiki/Harmonic_oscillator[classical spring^] that has been displaced from its equilibrium.
//What does part (c) tell you about the behavior of the quantum harmonic oscillator?
//How does this compare to the classical harmonic oscillator?
