[.qm-chapter.chap-3]
= Chapter 3: Formalism
include::shared_attributes.adoc[]

== Hilbert Space

=== Questions

* {q-num} [This problem is Griffiths 3.1 but is too simple to be his I.P.] Formally, a _vector space_ is a set ++\(S\)++ closed under linear combinations: if for all ++\(\vec u,\vec v\in S\)++ and for all ++\(a,b\in\mathbb C\)++, ++\(a\vec u+b\vec v\)++ is also in ++\(V\)++, then ++\(S\)++ is a vector space.
Show that the set of square-integrable functions does indeed form a vector space.

* {q-num} [Griffiths 3.2; same caveat as above] A vector space ++\(S\)++ is said to have an inner product ++\(\langle\cdot|\cdot\rangle\)++ when, for all ++\(u,v,w\in S\)++ and ++\(a,b\in\mathbb C\)++, the following properties hold:
** Conjugate symmetry: ++\(\langle v|u\rangle=\langle u|v\rangle^*\)++
** Nonnegativity: ++\(\langle u|u\rangle\ge 0\)++ (in particular, it's real), and ++\(\langle u|u \rangle=0\)++ if and only if ++\(u=\vec 0\)++ (++\(\vec 0\)++ the vector, not ++\(0\)++ the number)
** Linearity: ++\(\langle u|(av+bw)\rangle=a\langle u|v\rangle + b\langle u|w\rangle\)++

+
In addition, we define the _norm_ of a vector, corresponding to the length of a vector in ++\(\mathbb R^n\)++, to be ++\(\|v\|=\sqrt{\langle v|v\rangle}\)++. +
Show that the inner product below, defined on the set of square-integrable functions over domain ++\((a,b)\)++, satisfies these properties.
++\[\begin{align*}
\langle f|g\rangle:=\int_a^b f^*(x)g(x)\,dx
\end{align*}\]++


* {q-num}
A function ++\(f\)++ is said to be absolutely integrable when ++\(|f|\)++ is integrable.
.. Find a continuous real-valued function on ++\((0,\infty)\)++ that is absolutely integrable, but not square-integrable.
.. Find a continuous real-valued function on ++\((0,\infty)\)++ that is square-integrable, but not absolutely integrable.

+
.Solution
[%collapsible]
====
The "`trick`" is find functions that approach the ++\(x\)++- or ++\(y\)++-axis quickly enough to have a finite integral, but no longer do so when squared (part (a)) or square-rooted (part (b)).

[{sublist-style}]
. One example is the following function:
++\[\begin{align*}
f(x)=\begin{cases}
x^{-\frac{1}{2}}-1&x\le1\\
0&x\ge 1
\end{cases}
\end{align*}
\]++
+
image::fig-3.1.1-f1.svg[A function that is integrable but not square-integrable,width=500,role="text-center"]
+
This is because ++\(\int_0^1 x^n\,dx\)++ is finite if and only if ++\(n > -1\)++.
So ++\(x^{-\frac{1}{2}}\)++ is integrable, but its square, ++\(x^{-1}\)++, is not.

. One example is the following function:
++\[\begin{align*}
f(x)=\frac{1}{x+1}
\end{align*}
\]++
+
image::fig-3.1.1-f2.svg[A function that is square-integrable but not integrable,width=500,role="text-center"]
+
This is because ++\(\int_1^\infty x^n\,dx\)++ is finite if and only if ++\(n<-1\)++.
So ++\(x^{-1}\)++ is not integrable, but its square, ++\(x^{-2}\)++, is.
====

* [[Cauchy-Schwarz,3.1.4]]{q-num} Let's prove the Cauchy-Schwarz Inequality: ++\(|\langle x|y\rangle|^2\le \langle x|x\rangle\,\langle y|y\rangle\)++, or equivalently ++\(|\langle x|y\rangle|\le \|x\|\|y\|\)++ ("`the magnitude of the inner product is at most the product of the norms.`").
This inequality is pivotal in quantum mechanics because it is the basis of the uncertainty principle for all incompatible pairs of observables (i.e., hermitian operators with a nonzero commutator).
+
[{sublist-style}]
.. First, prove the Pythagorean Theorem for vectors: If ++\(x\)++ and ++\(y\)++ are orthogonal, then ++\(\|x+y\|^2=\|x\|^2+\|y\|^2\)++.
.. Use this to prove the Cauchy-Schwarz Inequality.
(Hint: let ++\(z=x-\frac{\langle y|x\rangle}{\langle y|y\rangle}y\)++.)
.. For which pairs of vectors ++\(x,y\)++ is the quantity on the left hand side maximized, i.e., when is the inequality an equality?

+
.Solution
[%collapsible%open]
====
[{sublist-style}]
.. Since ++\(x\)++ and ++\(y\)++ are orthogonal, ++\(\langle x|y\rangle=\langle x|y\rangle=0\)++. Now we simply apply the linearity of the inner product:
++\[\begin{align*}
\|x+y\|^2&=\langle x+y|x+y\rangle\\
&=\langle x|x\rangle+\langle x|y\rangle +\langle y|x\rangle +\langle y|y\rangle\\
&=\langle x|x\rangle+\langle y|y\rangle\\
&=\|x\|^2+\|y\|^2
\end{align*}\]++
.. First, if ++\(y=|0\rangle\)++, this is trivial; both sides of the inequality are 0.
So assume ++\(y\ne| 0\rangle\)++, from which it follows that ++\(\langle y|y\rangle\ne 0\)++.
As the hint suggests, let ++\(z=x-\frac{\langle y|x\rangle}{\langle y|y\rangle}y\)++. This reason for this choice of ++\(z\)++ will soon be clear:
++\[\begin{align*}
\left\langle y|z\right\rangle&=\left\langle y\middle| x-\frac{\langle y|x\rangle}{\langle y|y\rangle}y \right\rangle\\
&=\langle y|x\rangle-\frac{\langle y|x\rangle}{\langle y|y\rangle}\langle y|y\rangle\\
&=\langle y|x\rangle-\langle y|x\rangle\\
&=0
\end{align*}\]++
So ++\(y\)++ and ++\(z\)++ are orthogonal.
(In fact, ++\(\frac{\langle y|x\rangle}{\langle y|y\rangle}y\)++ is the projection of ++\(x\)++ onto ++\(y\)++, which when subtracted from ++\(x\)++ leaves the portion of ++\(x\)++ orthogonal to ++\(y\)++.)
Now, ++\(x=z+\frac{\langle y|x\rangle}{\langle y|y\rangle}y\)++, the sum of two orthogonal vectors.
And, of course, ++\(\|z\|\ge 0\)++.
So, applying the Pythagorean Theorem, we have
++\[\begin{align*}
\|x\|^2&=\|z\|^2+\left\|\frac{\langle y|x\rangle}{\langle y|y\rangle}y\right\|^2\\
&=\|z\|^2+\left|\frac{\langle y|x\rangle}{\|y\|^2}\right|^2\|y\|^2\\
&=\|z\|^2+\frac{|\langle y|x\rangle|^2}{\|y\|^2}\\
&\ge \frac{|\langle y|x\rangle|^2}{\|y\|^2}
\end{align*}\]++
Multiplying both sides by ++\(\|y\|^2\)++ and using the fact that ++\(|\langle y|x\rangle|=|\langle x|y\rangle|\)++, we obtain
++\[\|x\|^2\|y\|^2\ge |\langle x|y\rangle|^2\]++
as desired.
.. For this inequality to be an equality, we need ++\(\|z\|^2=0\)++, which implies ++\(x=\frac{\langle y|x\rangle}{\langle y|y\rangle}y\)++. So ++\(x\)++ must be a scalar multiple of ++\(y\)++ (which, in the finite-dimensional case, would mean they're parallel).
====

=== Demonstrations

== Observables

=== Questions
* {q-num} Show that if ++\(P=Q^\dagger Q\)++ for some operator ++\(Q\)++, then ++\(\langle f|Pf\rangle\ge 0\)++ for all ++\(f\)++.
+
.Solution
[%collapsible]
====
If ++\(Q\)++ is defined on domain ++\(\mathcal D\)++, then
++\[
\begin{align*}
\langle f|Pf\rangle&=\langle f|Q^\dagger Qf\rangle\\
&=\langle Qf| Qf\rangle\\
&=\int_\mathcal{D} |Qf|^2\,dx
\end{align*}
\]++

Since ++\(|Qf|^2\)++ is nonnegative, so is any integral of it.
====

* {q-num} Show that ++\(Q^{\dagger\dagger}=Q\)++ for any operator ++\(Q\)++. (In other words, show that the adjoint of the adjoint is the original operator.)
+
.Solution
[%collapsible]
====
Simply by the definition of the adjoint and the fact that ++\(\langle g|f\rangle=\langle f|g\rangle^*\)++, we have, for all ++\(f\)++ and ++\(g\)++,
++\[
\begin{align*}
\langle Q^{\dagger\dagger} f|g\rangle&=\langle f|Q^\dagger g\rangle\\
&=\langle Q^\dagger g|f\rangle^*\\
&=\langle g|Qf\rangle^*\\
&=\langle Qf|g\rangle^{**}\\
&=\langle Qf|g\rangle
\end{align*}
\]++

Now, because the inner product is linear,
++\[
\begin{align*}
0&=\langle Q^{\dagger\dagger} f|g\rangle-\langle Qf|g\rangle\\
&=\langle Q^{\dagger\dagger} f-Qf|g\rangle\\
&=\langle (Q^{\dagger\dagger} -Q)f|g\rangle
\end{align*}
\]++

In particular, taking ++\(g=(Q^{\dagger\dagger} -Q)f\)++, we have

++\[
\begin{align*}
0&=\langle (Q^{\dagger\dagger} -Q)f|(Q^{\dagger\dagger} -Q)f\rangle\\
&=|(Q^{\dagger\dagger} -Q)f|^2
\end{align*}
\]++

Hence ++\((Q^{\dagger\dagger} -Q)f=\vec 0\)++ (++\(\vec 0\)++ the vector/function, not ++\(0\)++ the number).
Since ++\(f\)++ was arbitrary, ++\(Q^{\dagger\dagger} -Q\)++ must be the zero operator, and so ++\(Q^{\dagger\dagger} =Q\)++.
====

== Eigenfunctions of a Hermitian Operator

=== Questions

* {q-num} find the eigenfunctions and eigenvalues of the position operator ++\(x\)++, defined by ++\(x(f)=xf\)++, and ++\(p\)++, defined by ++\(p(f)=-i\hbar \frac{\partial f}{\partial x}\)++.

* {q-num} Suppose that ++\(f\)++ is an eigenfunction of operators ++\(Q_1\)++ and ++\(Q_2\)++ with eigenvalues ++\(q_1\)++ and ++\(q_2\)++, respectively.
Show that ++\(f\)++ is an eigenfunction of the following operators, and find the corresponding eigenvalues.
+
[{sublist-style}]
. ++\(\alpha Q_1\)++ for ++\(\alpha\in\mathbb C \)++
. ++\(Q_1+Q_2\)++
. ++\(Q_1Q_2\)++
. ++\(Q_2Q_1\)++

+
.Solution
[%collapsible]
====
The following laws are helpful:

* Operator application is associative
* Operator application distributes over addition
* Scalars commute with everything

//

[{sublist-style}]
. ++\(((\alpha Q_1)f=\alpha (Q_1f)=\alpha q_1f\)++, so ++\(f\)++ is an eigenfunction of ++\(\alpha Q_1\)++ with eigenvalue ++\(\alpha q_1\)++.
. ++\((Q_1+Q_2)f=Q_1f+Q_2f=q_1f+q_2f=(q_1+q_2)f\)++, so ++\(f\)++ is an eigenfunction of ++\(Q_1+Q_2\)++ with eigenvalue ++\(q_1+q_2\)++.
. {blank}
++\[
\begin{align*}
(Q_1Q_2)f&=Q_1(Q_2f)\\
&=Q_1(q_2f)\\
&=q_2(Q_1f)\\
&=q_2q_1f
\end{align*}
\]++
So ++\(f\)++ is an eigenfunction of ++\(Q_1Q_2\)++ with eigenvalue ++\(q_1q_2\)++
. The proof proceeds exactly as above. The eigenvalue is again ++\(q_1q_2\)++. So, while operators may not commute, the eigenvalues of the product of two operators does not depend on the order of the product.
====

* {q-num} Find the eigenfunctions and eigenvalues of the operator ++\(\frac{d^n}{dx^n}\)++ for positive integer ++\(n\)++.
(Don't worry about whether the solutions are square-integrable.)
+
.Solution
[%collapsible]
====
For fixed ++\(q\ne 0\)++, solving ++\(\frac{d^n}{dx^n}f(x)=qf(x)\)++ yields
++\[ f_q(x)=\sum_{k=1}^{n}c_k \exp\left[(-1)^{2k/n}q^{1/n}x\right] \]++
where ++\(f_q\)++ is the eigenfunction belonging to eigenvalue ++\(q\)++, and the ++\(c_k\)++ are constants determined by the boundary conditions.
Evidently, every nonzero complex number is an eigenvalue.

If ++\(q=0\)++, then the solutions to ++\(\frac{d^n}{dx^n}f(x)=0\)++ are simply the polynomials of degree at most ++\(n-1\)++.

NOTE: This problem highlights the fact that the eigenfunctions of an operator depend on the _precise_ operator in question; ++\(\frac{d^n}{dx^n}-q\)++ is quite different from ++\(\frac{d^n}{dx^n}\)++ when ++\(q\ne0\)++.
====

== Generalized Statistical Interpretation

=== Questions

* {q-num} Recall that if ++\(A\)++ is an observable with (normalized) eigenvectors ++\(f_\alpha\)++, we can write
++\[\begin{align*}
\Psi&=\sum_{n} c_n f_n\quad \textrm{(discrete spectrum)}\\
\Psi&=\int_{\mathcal D} c_z f_z\,dz\quad \textrm{(continuous spectrum)}\\
\end{align*}\]++
and then due to the orthogonality of the eigenvectors of a hermitian operator, the coefficients are given by ++\(c_\alpha =\langle f_\alpha | \Psi\rangle\)++.
Show that this is equivalent to "`projecting`" ++\(\Psi\)++ onto ++\(f_\alpha\)++: if ++\(P_\alpha=|f_\alpha\rangle\langle f_\alpha|\)++, then ++\(P_\alpha|\Psi\rangle=c_\alpha |f_\alpha\rangle\)++.
+
.Solution
[%collapsible%open]
====
The computation is straightforward:
++\[\begin{align*}
P_\alpha|\Psi\rangle&=(|f_\alpha\rangle\langle f_\alpha|)|\Psi\rangle\\
&=|f_\alpha\rangle\ \langle f_\alpha|\Psi\rangle\\
&=\langle f_\alpha|\Psi\rangle\ |f_\alpha\rangle\\
&=c_\alpha |f_\alpha\rangle
\end{align*}\]++

[NOTE]
--
This is exactly why we can say that ++\(c_\alpha =\langle f_\alpha | \Psi\rangle\)++ tells you how much of ++\(f_\alpha\)++ is in ++\(\Psi\)++. Because the inner project with a normalized vector ++\(u\)++ is equvalent to a projection onto ++\(u\)++, the inner product picks out just the component corresponding to ++\(u\)++.
For a concrete example, consider the vector space ++\(\mathbb R^n\)++, where projecting a vector ++\(v\)++ onto the ++\(k\)++^th^ basis vector ++\(e_n\)++, i.e., computing ++\(\langle v|e_k\rangle\)++, picks out the ++\(k\)++^th^ component of ++\(v\)++ — that's what the components of a vector in ++\(\mathbb R^n\)++ _mean_.

The Fourier transform is nothing more than a projection of a function onto the complex exponentials ++\(e^{-i\omega x}\)++.
--
====

== The Uncertainty Principle

=== Questions

* {q-num} Show that the commutator of two hermitian operators is of the form ++\(iQ\)++ where ++\(Q\)++ is hermitian.
+
.Solution
[%collapsible%open]
====
Let ++\(A\)++ and ++\(B\)++ be two hermitian operators, i.e., ++\(A=A^\dagger\)++ and ++\(B=B^\dagger\)++.
Then
++\[\begin{align*}
[A,B]^\dagger&=(AB-BA)^\dagger\\
&=(AB)^\dagger-(BA)^\dagger\\
&=B^\dagger A^\dagger - A^\dagger B^\dagger\\
&=BA-AB\\
&=-[A,B]
\end{align*}\]++
Therefore,
++\[\begin{align*}
(-i[A,B])^\dagger&=(-i)^*[A,B]^\dagger\\
&=i(-[A,B])\\
&=-i[A,B]
\end{align*}\]++
So ++\(-i[A,B]\)++ is hermitian.
Letting ++\(Q=-i[A,B]\)++, we have ++\([A,B]=iQ\)++ with ++\(Q\)++ hermitian, as desired.

NOTE: The operators ++\(R\)++ for which ++\(R^\dagger=-R\)++ are known as https://en.wikipedia.org/wiki/Skew-Hermitian_matrix[_anti-hermitian_].
As we saw above, just as an imaginary number is ++\(i\)++ times a real number, an anti-hermitian matrix is ++\(i\)++ times a hermitian matrix.
And in the same way that hermitian operators are akin to real numbers (e.g., their eigenvalues are all real), anti-hermitian operators are akin to imaginary numbers (e.g., their eigenvalues are all imaginary).
====

* {q-num} The uncertainty principle ++\(\sigma_x \sigma_p\ge \frac{\hbar}{2}\)++ only holds in one dimension.
Show that in ++\(n\)++ dimensions, in which ++\(\hat x|f\rangle=\vec x f\)++ and ++\(\hat p|f\rangle=i\hbar \nabla f\)++, the uncertainty principle becomes ++\(\sigma_x \sigma_p\ge \frac{n\hbar}{2}\)++.
(Hint: what's ++\([x,p]\)++ with these new definitions of ++\(\hat x\)++ and ++\(\hat p\)++?)

== Vectors and Operators

=== Questions

* {q-num} Find the eigenvalues and normalized eigenvectors of
++\[A=\begin{pmatrix}4&2\\1&5\end{pmatrix}\]++
+
.Solution
[%collapsible]
====
We wish to solve ++\(A|x\rangle=\lambda |x\rangle\)++ with ++\(|x\rangle\ne |0\rangle\)++.
Subtracting ++\(\lambda|x\rangle\)++ from both sides and factoring, we obtain ++\((A-\lambda I)|x\rangle=|0\rangle\)++, where ++\(I\)++ is the identity matrix (of the correct dimensions; in this case, ++\(2\times 2\)++).
Since ++\(|x\rangle\ne |0\rangle\)++, ++\(A-\lambda I\)++ must be singular (non-invertible), which means its determinant is 0.
So, we have
++\[\begin{align*}
0&=\det (A-\lambda I)\\&=(4-\lambda)(5-\lambda)-1\cdot 2\\&=\lambda^2-9\lambda+18\\&=(\lambda-3)(\lambda-6)
\end{align*}\]++
So the eigenvalues are ++\(\lambda_1=3\)++ and ++\(\lambda_2=6\)++.

Now we must solve ++\(\lambda_i|x\rangle x=A|x\rangle\)++ for the concrete eigenvalues ++\(\lambda_1, \lambda_2\)++.
If ++\(|x\rangle=\begin{bmatrix}x\\y\end{bmatrix}\)++, then we find the eigenvectors corresponding to ++\(\lambda_1\)++ as follows:
++\[
\begin{align*}
3\begin{bmatrix}x\\y\end{bmatrix}&=\begin{pmatrix}4&2\\1&5\end{pmatrix}\begin{bmatrix}x\\y\end{bmatrix}=\begin{bmatrix}4x+2y\\x+5y\end{bmatrix}
\end{align*}
\]++
Since equal vectors must have equal components, we have the system of equations ++\(3x=4x+2y,3y=x+5y\)++.
This has solution ++\(x=-2y\)++, which means the eigenvectors corresponding to ++\(\lambda_1=3\)++ are of the form ++\(\begin{bmatrix}-2y\\y\end{bmatrix}\)++, which as a unit vector is ++\(\dfrac{1}{\sqrt{5}}\begin{bmatrix}-2\\1\end{bmatrix}\)++.

Similarly, for ++\(\lambda_2=6\)++, we obtain ++\(6x=4x+2y,6y=x+5y\)++ which has solution ++\(x=y\)++, so the unit eigenvector is ++\(\dfrac{1}{\sqrt{2}}\begin{bmatrix}1\\1\end{bmatrix}\)++.
====

* {q-num} What are the eigenvalues and normalized eigenvectors of a diagonal matrix ++\(A\)++ with diagonal entries ++\(m_1, \ldots, m_n\)++?
+
.Solution
[%collapsible]
====
An ++\(n\)++-dimensional matrix can have at most ++\(n\)++ linearly independent eigenvectors, so if we find ++\(n\)++ eigenvectors then we're done.
If we define ++\(v_k:=\)++ the ++\(k\)++^th^ column of the ++\(n\times n\)++ identity matrix — i.e., ++\(v_k\)++ is the vector whose only nonzero component is component ++\(k\)++, which is 1 — then clearly ++\(Av_k=m_k v_k\)++.
So the normalized eigenvalues are these ++\(v_k\)++ and the corresponding eigenvalues are ++\(\lambda_k=m_k\)++.
====

* {q-num} [This problem is technically in Griffiths but I imagine it's also in every linear algebra book ever written.] Suppose ++\(P\)++ is a projection operator, i.e., that it can be written as ++\(P=|a\rangle\langle a|\)++ for some unit vector ++\(a\)++.
+
[{sublist-style}]
. Show that ++\(P\)++ is _idempotent_, i.e., that ++\(P^2=P\)++.
(Corollary: ++\(P^n=P\)++ for every positive integer ++\(n\)++.)
. What are the eigenvalues of ++\(P\)++?
. What are the corresponding eigenvectors? (With ++\(P\)++ arbitrary, you can't write out the eigenvectors explicitly, so merely describe them in terms of ++\(a\)++.)

+
.Solution
[%collapsible]
====
[{sublist-style}]
. Every projection operator is of the form ++\(P=|a\rangle\langle a|\)++ where ++\(a\)++ is a unit vector.
So
++\[\begin{align*}
P^2&=(|a\rangle\langle a|)(|a\rangle\langle a|)\\
&=|a\rangle(\langle a|a\rangle)\langle a|\\
&=|a\rangle(1)\langle a|\\
&=|a\rangle\langle a|\\
&=P
\end{align*}\]++

. We wish to solve ++\(P|x\rangle=\lambda|x\rangle\)++ (with ++\(|x\rangle\ne |0\rangle\)++).
By the corollary to part (a), for every positive integer ++\(n\)++, we have ++\(\lambda^{n+1}|x\rangle=P^{n+1}|x\rangle=P|x\rangle=\lambda x\)++, and so ++\((\lambda^{n+1}-\lambda)|x\rangle=|0\rangle\)++.
Since ++\(|x\rangle\ne |0\rangle\)++, we have ++\(\lambda^{n+1}=\lambda\)++.
The only values of ++\(\lambda\)++ for which this holds for all ++\(n\)++ are ++\(\lambda_0=0\)++ and ++\(\lambda_1=1\)++, so those are the two eigenvalues.
. We simply solve for ++\(|x\rangle\)++ corresponding to ++\(\lambda_0\)++:
++\[
|a\rangle\langle a|x\rangle=P|x\rangle=\lambda_0|x\rangle=|0\rangle
\]++
++\(|a\rangle\ne|0\rangle\)++, so ++\(\langle a|x\rangle=0\)++.
Thus the eigenvectors corresponding to ++\(\lambda_0=0\)++ are the vectors orthogonal to ++\(a\)++.
+
Now we solve for ++\(|x\rangle\)++ corresponding to ++\(\lambda_1\)++: ++\[
|a\rangle\langle a|x\rangle=P|x\rangle=\lambda_1|x\rangle=|x\rangle
\]++
Since ++\(\langle a|x\rangle\)++ is just a scalar, the eigenvectors corresponding to ++\(\lambda_1=1\)++ are the vectors parallel to ++\(a\)++.
====

* {q-num} For a matrix ++\(A\)++, the _matrix exponential_ is defined by replacing ++\(x\)++ in the power series for ++\(e^x\)++ with ++\(A\)++:
++\[e^{A}:=\sum_{n=0}^\infty \frac{A^n}{n!}.\]++
(By analogy with numbers, ++\(A^0\)++ is defined to be the identity operator — perhaps the summation should be written ++\(e^{A}=I+\sum_{n=1}^\infty \frac{A^n}{n!}\)++)
The matrix exponential ++\(e^A\)++ shares some properties with the ordinary exponential ++\(e^z\)++ over complex numbers:
+
[{sublist-style}]
.. Show that the matrix exponential of the zero operator is the identity operator. (Analog: ++\(e^0=1\)++.)
.. Show that ++\(e^{A^\dagger}=(e^A)^\dagger\)++. (Analog: ++\(e^{z^*}=(e^z)^*\)++.)
.. Show that if ++\(A\)++ is hermitian then so is ++\(e^A\)++. (Analog: the exponential of a real number is real.)
.. Under what conditions on matrices ++\(A\)++ and ++\(B\)++ does it hold that ++\(e^{A+B}=e^Ae^B\)++? (Analog: ++\(e^{z+w}=e^z e^w\)++, always.)

+
.Solution
[%collapsible]
====
[{sublist-style}]
. Let ++\(\mathbf 0\)++ denote the zero operator.
++\(e^{\mathbf 0}=\sum_{n=0}^\infty \frac{\mathbf 0^n}{n!}\)++.
The only nonzero term of this sum is the ++\(n=0\)++ term, which by definition is the identity matrix.
. First, note that since ++\((AB)^\dagger=B^\dagger A^\dagger\)++ for all operators ++\(A,B\)++, we have ++\((A^\dagger)^n=(A^n)^\dagger\)++.
Also recall that ++\((A+B)^\dagger=A^\dagger+B^\dagger\)++.
Then,
++\[\begin{align*}
e^{A^\dagger}&=\sum_{n=0}^\infty \frac{(A^\dagger)^n}{n!}\\
&=\sum_{n=0}^\infty \frac{(A^n)^\dagger}{n!}\\
&=\left(\sum_{n=0}^\infty \frac{A^n}{n!}\right)^\dagger\\
&=(e^A)^\dagger
\end{align*}\]++
as desired.
. Recall that the inner product is linear. Also, if ++\(A\)++ is hermitian, then ++\((A^n)^\dagger=(A^\dagger)^n=A^n\)++, so ++\(A^n\)++ is also hermitian. Then,
++\[\begin{align*}
\langle f|e^A g\rangle&=\left\langle f\middle|\sum_{n=0}^\infty \frac{A^n}{n!} g\right\rangle\\
&=\sum_{n=0}^\infty\langle f|A^n g\rangle\\
&=\sum_{n=0}^\infty\langle A^n f|g\rangle\\
&=\left\langle\sum_{n=0}^\infty A^n f\middle|g\right\rangle\\
&=\langle e^A f|g\rangle
\end{align*}\]++
as desired.
. For ++\(e^{A+B}=e^A e^B\)++ to hold, ++\(A\)++ and ++\(B\)++ must commute.
If and only if ++\(A\)++ and ++\(B\)++ commute, we have
++\[\begin{align*}
(A+B)^n&=\sum_{k=0}^n \binom{n}{k}A^kB^{n-k}
\end{align*}\]++
where ++\(\binom{n}{k}:=\frac{n!}{k!(n-k)!}\)++ denotes the binomial coefficient.
For instance, regardless of whether ++\(A\)++ and ++\(B\)++ commute,
++\[\begin{align*}
(A+B)^3&=(A+B)(A+B)(A+B)\\
&=(A^3+AB+BA+B^2)(A+B)\\
&=A^2+ABA+BA^2+B^2A\\
&\phantom{=}+A^2B+AB^2+BAB+B^3
\end{align*}\]++
Only if ++\(A\)++ and ++\(B\)++ commute can this be simplified to ++\(A^3+3A^2B+3AB^2+3B^3\)++.
+
Then,
++\[\begin{align*}
e^{A+B}&=\sum_{n=0}^\infty \frac{(A+B)^n}{n!}\\
&=\sum_{n=0}^\infty \left(\frac{1}{n!}\sum_{k=0}^n\binom{n}{k}A^kB^{n-k}\right)\\
&=\sum_{n=0}^\infty \sum_{k=0}^n \frac{A^k}{k!}\frac{B^{n-k}}{(n-k)!}\\
&=\left(\sum_{n=0}^\infty \frac{A^n}{n!}\right)\left(\sum_{n=0}^\infty \frac{B^n}{n!}\right)\\
&=e^Ae^B
\end{align*}\]++
as desired.

[sidebar]
How did we turn ++\(\sum_{n=0}^\infty \sum_{k=0}^n \frac{A^k}{k!}\frac{B^{n-k}}{(n-k)!}\)++ into ++\(\left(\sum_{n=0}^\infty \frac{A^n}{n!}\right)\left(\sum_{n=0}^\infty \frac{B^n}{n!}\right)\)++?
This is just an advanced application of the distributive property.
Simply write out the second expression by hand, apply the distributive property, and group terms according to the sum of the powers of ++\(A\)++ and ++\(B\)++ (so that e.g., the ++\(A^3\)++, ++\(A^2B\)++, ++\(AB^2\)++, and ++\(B^3\)++ terms are grouped together).
You'll see the first expression appear.
====

* {q-num} Let ++\(\hat x\)++ be the operator corresponding to the ++\(x\)++ observable, which is multiplication by ++\(x\)++ (in position space).
Show that ++\(e^{\hat x}|f\rangle=e^x |f\rangle\)++, i.e., the operator exponential of ++\(\hat x\)++ is multiplication by ++\(e^x\)++.

* {q-num} Show that the solution to the differential equation ++\(\frac{d}{dt}|x(t)\rangle= A|x(t)\rangle\)++ with initial condition ++\(|x(0)\rangle=|x_0\rangle\)++, where ++\(A\)++ is a constant nonzero operator, is ++\(|x(t)\rangle=e^{At}|x_0\rangle\)++.
+
NOTE: This exactly mirrors the scalar-valued differential equation ++\(\frac{d}{dt}y(t)=ky(t),y(0)=y_0\)++ with ++\(k\)++ constant, which has solution ++\(y(t)=e^{kt}y_0\)++.
+
.Solution
[%collapsible]
====
First we'll check the initial condition:
++\[e^{A\cdot 0}|x_0\rangle=I|x_0\rangle=|x_0\rangle\]++
Now we'll check that the proposed solution satisfies the differential equation.
++\[\begin{align*}
\frac{d}{dt}\Big|x(t)\Big\rangle&=\frac{d}{dt}\Big|\left(e^{At}|x_0\rangle\right)\Big\rangle\\
&=\left(\frac{d}{dt}e^{At}\right)|x_0\rangle\\
&=\frac{d}{dt}\left(\sum_{n=0}^\infty \frac{(At)^n}{n!}\right)|x_0\rangle\\
&=\left(\sum_{n=1}^\infty \frac{A^n\,nt^{n-1}}{n!}\right)|x_0\rangle\\
&=A\left(\sum_{n=1}^\infty \frac{A^{n-1}t^{n-1}}{(n-1)!}\right)|x_0\rangle\\
&=A\left(\sum_{n=0}^\infty \frac{A^{n}t^{n}}{n!}\right)|x_0\rangle\\
&=Ae^{At}|x_0\rangle\\
&=A|x(t)\rangle
\end{align*}\]++
as desired.
====
